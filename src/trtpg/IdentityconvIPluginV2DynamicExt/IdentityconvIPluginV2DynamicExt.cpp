/*
 * SPDX-FileCopyrightText: Copyright (c) <year> NVIDIA CORPORATION & AFFILIATES. All rights
 * reserved. SPDX-License-Identifier: MIT
 *
 * Permission is hereby granted, free of charge, to any person obtaining a
 * copy of this software and associated documentation files (the "Software"),
 * to deal in the Software without restriction, including without limitation
 * the rights to use, copy, modify, merge, publish, distribute, sublicense,
 * and/or sell copies of the Software, and to permit persons to whom the
 * Software is furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 * THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 * DEALINGS IN THE SOFTWARE.
 */

/*
 * This file is originally generated by NVIDIA-AI-IOT/tensorrt_plugin_generator,
 * GitHub repo: https://github.com/NVIDIA-AI-IOT/tensorrt_plugin_generator
 */

#ifndef DEBUG_PLUGIN
#define DEBUG_PLUGIN 1  // set debug mode, if you want to see the api call, set it to 1
#endif

#include "IdentityconvIPluginV2DynamicExt.h"

#include <cassert>
#include <cstring>
#include <iostream>
#include <vector>

#include "NvInfer.h"

#if DEBUG_PLUGIN
#define DEBUG_LOG(...)                                                                    \
  {                                                                                       \
    std::cout << " ----> debug <---- call " << "[" << __FILE__ << ":" << __LINE__ << "][" \
              << __FUNCTION__ << "]" << std::endl;                                        \
  }
#else
#define DEBUG_LOG(...)
#endif

using namespace nvinfer1;

namespace {
const char* PLUGIN_VERSION{"1"};
const char* PLUGIN_NAME{"IdentityConv"};
}  // namespace

// Static class fields initialization
PluginFieldCollection IdentityconvIPluginV2DynamicExtCreator::mFC{};
std::vector<PluginField> IdentityconvIPluginV2DynamicExtCreator::mPluginAttributes;

REGISTER_TENSORRT_PLUGIN(IdentityconvIPluginV2DynamicExtCreator);

// Helper function for serializing plugin
template <typename T>
void writeToBuffer(char*& buffer, const T& val) {
  *reinterpret_cast<T*>(buffer) = val;
  buffer += sizeof(T);
}

// Helper function for deserializing plugin
template <typename T>
void readFromBuffer(const char*& buffer, T& val) {
  val = *reinterpret_cast<const T*>(buffer);
  buffer += sizeof(T);
}

IdentityconvIPluginV2DynamicExt::IdentityconvIPluginV2DynamicExt(IdentityconvAttrs params) {
  DEBUG_LOG();
  mParams = params;
}

IdentityconvIPluginV2DynamicExt::IdentityconvIPluginV2DynamicExt(const void* data, size_t length) {
  DEBUG_LOG();
  // Deserialize in the same order as serialization
  const char* d = static_cast<const char*>(data);
  const char* a = d;

  readFromBuffer(d, mParams.group);
  readFromBuffer(d, mParams.num_kernel_shape);
  mParams.kernel_shape.resize(mParams.num_kernel_shape);
  for (size_t i = 0; i < mParams.num_kernel_shape; i++) {
    readFromBuffer(d, mParams.kernel_shape[i]);
  }
  readFromBuffer(d, mParams.num_pads);
  mParams.pads.resize(mParams.num_pads);
  for (size_t i = 0; i < mParams.num_pads; i++) {
    readFromBuffer(d, mParams.pads[i]);
  }
  readFromBuffer(d, mParams.num_strides);
  mParams.strides.resize(mParams.num_strides);
  for (size_t i = 0; i < mParams.num_strides; i++) {
    readFromBuffer(d, mParams.strides[i]);
  }

  assert(d == (a + length));
}

// -------------------- IPluginV2 ----------------------

const char* IdentityconvIPluginV2DynamicExt::getPluginType() const IS_NOEXCEPT {
  DEBUG_LOG();
  return PLUGIN_NAME;
}

const char* IdentityconvIPluginV2DynamicExt::getPluginVersion() const IS_NOEXCEPT {
  DEBUG_LOG();
  return PLUGIN_VERSION;
}

int IdentityconvIPluginV2DynamicExt::getNbOutputs() const IS_NOEXCEPT {
  DEBUG_LOG();
  return 1;
}

// IMPORTANT: Memory allocated in the plug-in must be freed to ensure no memory leak.
// If resources are acquired in the initialize() function, they must be released in the terminate()
// function. All other memory allocations should be freed, preferably in the plug-in class
// destructor or in the destroy() method.

// Initialize the layer for execution.
// e.g. if the plugin require some extra device memory for execution. allocate in this function.
// for details please refer to
// https://docs.nvidia.com/deeplearning/tensorrt/api/c_api/classnvinfer1_1_1_i_plugin_v2.html
int IdentityconvIPluginV2DynamicExt::initialize() IS_NOEXCEPT {
  DEBUG_LOG();
  return 0;
}

void IdentityconvIPluginV2DynamicExt::terminate() IS_NOEXCEPT {
  DEBUG_LOG();
  // Release resources acquired during plugin layer initialization
}

size_t IdentityconvIPluginV2DynamicExt::getSerializationSize() const IS_NOEXCEPT {
  DEBUG_LOG();
  size_t size = 0;

  // int32_t group
  size += sizeof(int32_t);
  // size_t num_kernel_shape
  size += sizeof(size_t);
  // std::vector<int32_t> kernel_shape
  size += (sizeof(int32_t) * mParams.num_kernel_shape);
  // size_t num_pads
  size += sizeof(size_t);
  // std::vector<int32_t> pads
  size += (sizeof(int32_t) * mParams.num_pads);
  // size_t num_strides
  size += sizeof(size_t);
  // std::vector<int32_t> strides
  size += (sizeof(int32_t) * mParams.num_strides);

  // the size will equal to the length when deserializing.
  return size;
}

void IdentityconvIPluginV2DynamicExt::serialize(void* buffer) const IS_NOEXCEPT {
  DEBUG_LOG();
  char* d = static_cast<char*>(buffer);
  const char* a = d;

  writeToBuffer(d, mParams.group);
  writeToBuffer(d, mParams.num_kernel_shape);
  assert(mParams.kernel_shape.size() == mParams.num_kernel_shape);
  for (size_t i = 0; i < mParams.num_kernel_shape; i++) {
    writeToBuffer(d, mParams.kernel_shape[i]);
  }
  writeToBuffer(d, mParams.num_pads);
  assert(mParams.pads.size() == mParams.num_pads);
  for (size_t i = 0; i < mParams.num_pads; i++) {
    writeToBuffer(d, mParams.pads[i]);
  }
  writeToBuffer(d, mParams.num_strides);
  assert(mParams.strides.size() == mParams.num_strides);
  for (size_t i = 0; i < mParams.num_strides; i++) {
    writeToBuffer(d, mParams.strides[i]);
  }

  assert(d == a + getSerializationSize());
}

void IdentityconvIPluginV2DynamicExt::destroy() IS_NOEXCEPT {
  DEBUG_LOG();
  // This gets called when the network containing plugin is destroyed
  delete this;
}

void IdentityconvIPluginV2DynamicExt::setPluginNamespace(const char* pluginNamespace) IS_NOEXCEPT {
  DEBUG_LOG();
  mNamespace = pluginNamespace;
}

const char* IdentityconvIPluginV2DynamicExt::getPluginNamespace() const IS_NOEXCEPT {
  DEBUG_LOG();
  return mNamespace.c_str();
}

// -------------------- IPluginV2Ext --------------------

DataType IdentityconvIPluginV2DynamicExt::getOutputDataType(int32_t index,
                                                            DataType const* inputTypes,
                                                            int32_t nbInputs) const IS_NOEXCEPT {
  DEBUG_LOG();
  assert(index < 1);
  assert(inputTypes != nullptr);
  assert(nbInputs == 2);
  if (index == 0) {
    if (inputTypes[0] == DataType::kFLOAT && inputTypes[1] == DataType::kFLOAT) {
      return DataType::kFLOAT;
    }
    if (inputTypes[0] == DataType::kHALF && inputTypes[1] == DataType::kFLOAT) {
      return DataType::kFLOAT;
    }
  }
  // Default: return the datatype of the first input or datatype kFLOAT
  return nbInputs == 0 ? DataType::kFLOAT : inputTypes[0];
}

// -------------------- IPluginV2DynamicExt ------------------

IPluginV2DynamicExt* IdentityconvIPluginV2DynamicExt::clone() const IS_NOEXCEPT {
  DEBUG_LOG();
  auto plugin = new IdentityconvIPluginV2DynamicExt(mParams);
  plugin->setPluginNamespace(mNamespace.c_str());
  return plugin;
}

// To implement the output dimension, please refer to
// getOutputDimensions:
// https://docs.nvidia.com/deeplearning/tensorrt/api/c_api/classnvinfer1_1_1_i_plugin_v2_dynamic_ext.html#a2ad948f8c05a6e0ae4ab4aa92ceef311
// IExprBuilder:
// https://docs.nvidia.com/deeplearning/tensorrt/api/c_api/classnvinfer1_1_1_i_expr_builder.html
DimsExprs IdentityconvIPluginV2DynamicExt::getOutputDimensions(
    int32_t outputIndex, DimsExprs const* inputs, int32_t nbInputs,
    IExprBuilder& exprBuilder) IS_NOEXCEPT {
  DEBUG_LOG();
  assert(outputIndex < 1);
  assert(inputs != nullptr);
  assert(nbInputs == 2);
  DimsExprs output;
  if (outputIndex == 0) {
    output.nbDims = 4;
    output.d[0] = exprBuilder.constant(1);
    output.d[1] = exprBuilder.constant(3);
    output.d[2] = exprBuilder.constant(480);
    output.d[3] = exprBuilder.constant(960);
  }
  return output;
}

bool IdentityconvIPluginV2DynamicExt::supportsFormatCombination(int32_t pos,
                                                                PluginTensorDesc const* inOut,
                                                                int32_t nbInputs,
                                                                int32_t nbOutputs) IS_NOEXCEPT {
  DEBUG_LOG();
  bool is_supported = false;
  if (pos == 0) {
    is_supported =
        (inOut[pos].type == DataType::kFLOAT && inOut[pos].format == TensorFormat::kLINEAR) ||
        (inOut[pos].type == DataType::kHALF && inOut[pos].format == TensorFormat::kLINEAR);
  }
  if (pos == 1) {
    is_supported =
        (inOut[pos].type == DataType::kFLOAT && inOut[pos].format == TensorFormat::kLINEAR) ||
        (inOut[pos].type == DataType::kFLOAT && inOut[pos].format == TensorFormat::kLINEAR);
  }
  if (pos == 2) {
    is_supported =
        (inOut[0].type == DataType::kFLOAT && inOut[0].format == TensorFormat::kLINEAR &&
         inOut[1].type == DataType::kFLOAT && inOut[1].format == TensorFormat::kLINEAR &&
         inOut[pos].type == DataType::kFLOAT && inOut[pos].format == TensorFormat::kLINEAR) ||
        (inOut[0].type == DataType::kHALF && inOut[0].format == TensorFormat::kLINEAR &&
         inOut[1].type == DataType::kFLOAT && inOut[1].format == TensorFormat::kLINEAR &&
         inOut[pos].type == DataType::kFLOAT && inOut[pos].format == TensorFormat::kLINEAR);
  }

  return is_supported;
}

void IdentityconvIPluginV2DynamicExt::configurePlugin(DynamicPluginTensorDesc const* in,
                                                      int32_t nbInputs,
                                                      DynamicPluginTensorDesc const* out,
                                                      int32_t nbOutputs) IS_NOEXCEPT {
  DEBUG_LOG();
  // This function is called by the builder prior to initialize().
  // It provides an opportunity for the layer to make algorithm choices on the basis of I/O
  // PluginTensorDesc
}

size_t IdentityconvIPluginV2DynamicExt::getWorkspaceSize(PluginTensorDesc const* inputs,
                                                         int32_t nbInputs,
                                                         PluginTensorDesc const* outputs,
                                                         int32_t nbOutputs) const IS_NOEXCEPT {
  DEBUG_LOG();
  // Find the workspace size required by the layer.
  // This function is called during engine startup, after initialize().
  // The workspace size returned should be sufficient for any batch size up to the maximum.
  return 0;
}

// TODO: implement by user
// The actual plugin execution func.
int32_t IdentityconvIPluginV2DynamicExt::enqueue(PluginTensorDesc const* inputDesc,
                                                 PluginTensorDesc const* outputDesc,
                                                 void const* const* inputs, void* const* outputs,
                                                 void* workspace, cudaStream_t stream) IS_NOEXCEPT {
  DEBUG_LOG();
  assert(inputDesc[0].dims.nbDims == outputDesc[0].dims.nbDims);
  size_t size_bytes = 1;
  for (int i = 0; i < inputDesc[0].dims.nbDims; i++) {
    size_bytes *= inputDesc[0].dims.d[i];
  }
  if (inputDesc[0].type == DataType::kINT8) {
    size_bytes *= 1;
  } else if (inputDesc[0].type == DataType::kHALF) {
    size_bytes *= 2;
  } else if (inputDesc[0].type == DataType::kFLOAT) {
    size_bytes *= 4;
  } else {
    assert(false);
  }
  const cudaError_t status =
      cudaMemcpyAsync(outputs[0], inputs[0], size_bytes, cudaMemcpyDeviceToDevice, stream);
  return 0;
}

// -------------------- IPluginCreator ------------------

IdentityconvIPluginV2DynamicExtCreator::IdentityconvIPluginV2DynamicExtCreator() {
  DEBUG_LOG();
  mPluginAttributes.clear();
  // Describe IdentityconvIPluginV2DynamicExt's required PluginField arguments
  mPluginAttributes.emplace_back(PluginField("group", nullptr, PluginFieldType::kINT32, 1));
  mPluginAttributes.emplace_back(PluginField("kernel_shape", nullptr, PluginFieldType::kINT32, 1));
  mPluginAttributes.emplace_back(PluginField("pads", nullptr, PluginFieldType::kINT32, 1));
  mPluginAttributes.emplace_back(PluginField("strides", nullptr, PluginFieldType::kINT32, 1));

  // Fill PluginFieldCollection with PluginField arguments metadata
  mFC.nbFields = mPluginAttributes.size();
  mFC.fields = mPluginAttributes.data();
}

const char* IdentityconvIPluginV2DynamicExtCreator::getPluginName() const IS_NOEXCEPT {
  DEBUG_LOG();
  return PLUGIN_NAME;
}

const char* IdentityconvIPluginV2DynamicExtCreator::getPluginVersion() const IS_NOEXCEPT {
  DEBUG_LOG();
  return PLUGIN_VERSION;
}

const PluginFieldCollection* IdentityconvIPluginV2DynamicExtCreator::getFieldNames() IS_NOEXCEPT {
  DEBUG_LOG();
  return &mFC;
}

IPluginV2DynamicExt* IdentityconvIPluginV2DynamicExtCreator::createPlugin(
    const char* name, const PluginFieldCollection* fc) IS_NOEXCEPT {
  DEBUG_LOG();
  const PluginField* fields = fc->fields;
  int nbFields = fc->nbFields;
  IdentityconvAttrs params;
  for (int i = 0; i < nbFields; ++i) {
    if (!strcmp(fields[i].name, "group")) {
      params.group = *(reinterpret_cast<const int32_t*>(fields[i].data));
    }
    if (!strcmp(fields[i].name, "kernel_shape")) {
      params.num_kernel_shape = fields[i].length;
      params.kernel_shape.resize(params.num_kernel_shape);
      for (int j = 0; j < fields[i].length; j++) {
        params.kernel_shape[j] = (reinterpret_cast<const int32_t*>(fields[i].data))[j];
      }
    }
    if (!strcmp(fields[i].name, "pads")) {
      params.num_pads = fields[i].length;
      params.pads.resize(params.num_pads);
      for (int j = 0; j < fields[i].length; j++) {
        params.pads[j] = (reinterpret_cast<const int32_t*>(fields[i].data))[j];
      }
    }
    if (!strcmp(fields[i].name, "strides")) {
      params.num_strides = fields[i].length;
      params.strides.resize(params.num_strides);
      for (int j = 0; j < fields[i].length; j++) {
        params.strides[j] = (reinterpret_cast<const int32_t*>(fields[i].data))[j];
      }
    }
  }

  return new IdentityconvIPluginV2DynamicExt(params);
}

IPluginV2DynamicExt* IdentityconvIPluginV2DynamicExtCreator::deserializePlugin(
    const char* name, const void* serialData, size_t serialLength) IS_NOEXCEPT {
  DEBUG_LOG();
  return new IdentityconvIPluginV2DynamicExt(serialData, serialLength);
}

void IdentityconvIPluginV2DynamicExtCreator::setPluginNamespace(const char* libNamespace)
    IS_NOEXCEPT {
  DEBUG_LOG();
  mNamespace = libNamespace;
}

const char* IdentityconvIPluginV2DynamicExtCreator::getPluginNamespace() const IS_NOEXCEPT {
  DEBUG_LOG();
  return mNamespace.c_str();
}
